[TOC]

# 个人技术提升

## MAVEN

### pom文件依赖间关系


```
    <parent>
        <groupId>com.acca.opra</groupId>
        <artifactId>opra-upl</artifactId>
        <version>0.5</version>
    </parent>

    <artifactId>opra-upl-api</artifactId>
    <packaging>jar</packaging>
    <description>交付子系统接口</description>

    <name>${project.artifactId}</name>
    <url>http://maven.apache.org</url>

    <properties>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    </properties>
    
 理解：与java的继承关系一致，parent表示父类接口/类，子依赖会自动继承父依赖的jar不用再次引入；若是父类依赖不满足现有扩展所需依赖，子类自行导入即可。（同一依赖在父依赖中导入和子依赖中均导入（重复依赖） 不同版本会有冲突 maven 会报错）
```

```
标签：
<parent>:是非必须在pom中存在的.
<dependencyManagement>:
定义的只是依赖的声明，并不实现引入，因此子项目需要显式的声明需要用的依赖；
多个子项目都引用同一样依赖，则可以避免在每个使用的子项目里都声明一个版本号，当想升级或切换到另一个版本时，只需要在顶层父容器里更新，而不需要逐个修改子项目；
若某个子项目需要另外的一个版本，只需要声明version。
```

```
实例定义父依赖
  <groupId>com.acca.opra</groupId>
  <artifactId>opra-upl-parent</artifactId>
  <version>0.5</version>
  <packaging>pom</packaging>
  父依赖中一般不会有代码，简单的目录结构如下
  
```

![](C:\Users\zhouf\Desktop\个人技术提升题解汇总\maven\maven项目结构实体.png)

## Redis

### 安装步骤

![redis安装步骤](C:\Users\zhouf\Desktop\个人技术提升题解汇总\redis\redis安装步骤.jpg)

### Redis特征
存储量大（K-V 均是512M）具有多种数据类型的单线程key-value键值对内存数据库，
支持持久化(aof.rdb)和集群,可以实现主从复制，读写分离，并且部署配置简单。

###数据删除策略
定期删除 + 懒惰删除策略。
设置过过期时间的key都会存在一个字典中
定期删除：
默认100ms 最多设置成25ms；
每次随机抽取 20 个 key；
删除这 20 个key中过期的key
如果过期的 key 比例超过 1/4，就重复步骤 1，继续删除。
惰性删除：
在过期key比例不超过1/4的情况下，key已过期，只能等用户访问key时发现已过期，就
将其删除

### Redis 基本类型
String、List、Set、Sorted Set、hashes

### EXPIRE、PERSIST SETEX

```
expire: 设置过期时间   
persist: 移除过期时间
setex：操作是原子性的  与 expire一起使用
```

### 数据淘汰策略

```
1. noeviction：当内存使用超过配置的时候会返回错误，不会驱逐任何键,读删操作还能用
2. allkeys-lru：加入键的时候，如果过限，首先通过LRU算法驱逐最久没有使用的键
3. volatile-lru：加入键的时候如果过限，首先从设置了过期时间的键集合中驱逐最久没有使用的键
4. allkeys-random：加入键的时候如果过限，从所有key随机删除
5. volatile-random：加入键的时候如果过限，从过期键的集合中随机驱逐
6. volatile-ttl：从配置了过期时间的键中驱逐马上就要过期的键
7. volatile-lfu：从所有配置了过期时间的键中驱逐使用频率最少的键
8. allkeys-lfu：从所有键中驱逐使用频率最少的键

LRU(Least Recently Used):LRU是淘汰最长时间没有被使用。
	新增数据放队尾，超出队列阈值就删除队头；修改和访问将数据放队尾。
LFU(Least Frequently Used):LFU是淘汰一段时间内，使用次数最少。（redis4.0诞生）

库中存放的数据在数据集大小到达一定量时会执行淘汰策略将数据精细化
```

![](C:\Users\zhouf\Desktop\个人技术提升题解汇总\redis\redis LRU算法图解.jpg)

### 缓存雪崩、缓存穿透与缓存击穿
缓存穿透：在有缓存服务器的情况下，总是被恶意程序查询不存在的key绕过直接访问后端请求数据，造成后端压力过大。

```
防止：
对查询为空的key也进行缓存，过期时间不应过长；
将所有存在的key存放到BitMap与访问key做匹配（redis插件 布隆过滤器）； 
```

缓存击穿：在key刚过期的时间点同时有大批请求，造成后端压力激增数据库服务器崩溃。

```
防止：
使用互斥锁：当缓存失效时，不立即访问DB，先Redis setnx设置互斥锁成功后再访问DB并回设缓存，否则再次访问缓存。
永远不过期：物理不过期，但逻辑过期（后台异步线程去刷新）。
```

缓存雪崩：缓存服务器关闭或多个key同时过期时，后端压力激增导致系统崩溃。

```
防止：
限制访问后端的线程数量或启用队列进行减压；
采用二级缓存；
将key的过期时间设置不一样，分散时间点。
```



### 视频未懂点 ：05Redis 哨兵 主从复制

##  JUC 

```
多线程情况少用list Set 多用quenue
ConcurrentHashMap 写效率低 读取效率极高
ConcurrentSkipListMap：跳表（redis sort_set也是这种数据结构）
ConcurrentLinkedDeque：CAS
ConcurrentLinkedQueue：CAS的双端队列

CopyOnWriteArrayList、CopyOnWriteArraySet...CopyOnxxxx：对写操作进行加锁ReentrantLock

LinkedBlockingQueue：无界队列（最大Integer.MAX_VALUE）FIFO tail存放的是最新进入的队列数据 head是队列中存在时间最长的数据(线程池高频使用)
LinkedTransferQueue：FIFO
LinkedBlockingDeque：双端阻塞队列（最大Integer.MAX_VALUE）
ArrayBlockingQueue：使用ReentrantLock实现 可以实现生产者消费者
PriorityBlockingQueue:ReentrantLock（CAS +volatile）实现
DelayQueue:使用PriorityQueue与ReentrantLock（CAS +volatile）实现
SynchronousQueue：容量为零，不能进行数据添加只能用于给另一个线程传递数据（Exchanger）CAS+Volatile+LockSupport (线程池高频使用)

```

## 多线程

```
Callable:Runnable +return
Future:存储执行的将来才会产生的结果
FutureTask:Callable+Future
CompletableFuture:管理多个Future的结果


ThreadPoolExecutor
7个参数：
corePoolSize –保留在池中的线程数（即使它们处于空闲状态），除非设置了allowCoreThreadTimeOut
maximumPoolSize –池中允许的最大线程数
keepAliveTime –当线程数大于内核数时，这是多余的空闲线程将在终止之前等待新任务的最长时间。
unit – keepAliveTime参数的时间单位
workQueue –用于在执行任务之前保留任务的队列。 此队列将仅保存execute方法提交的Runnable任务。
handler –因达到线程边界和队列容量而被阻止执行时使用的处理程序
threadFactory: 线程工厂(看看阿里华山派)
ForkJoinPool：
-分解汇总的任务
-用很少的线程可以执行很多的任务（子任务）TPE做不到先执行子任务
-CPU密集型
```



## JVM



## 多线程高并发

协程/纤程:绿色线程，用户管理而非OS管理的线程

线程：

https://blog.csdn.net/GKTDSR/article/details/107285233





## Zookeeper

这块暂时没学习过 没看懂 需要视频学习

不要把zookeeper 当数据库使用，每个节点容量大小1M，基于内存，有主变为无主模式再恢复到有主模式耗时在200ms左右，复制集群，leader是单机的，写操作都是leader进行，或者follower收到转发给leader进行创建，创建完成之后广播（每个follower都有一个队列FIFO）给所有follower

### 保证/特征

```
顺序一致性：来自客户端的更新将按照发送的顺序应用。
原子性：更新成功或失败。没有部分结果。
单个系统映像：无论客户端连接到哪个服务器，客户端都将看到相同的服务视图。
可靠性：应用更新后，此更新将一直持续到客户端覆盖更新为止(持久化)。
及时性：保证系统的客户视图在特定时间内是最新的(最终一致性)。
```

PAXOS ：目前唯一的分布式一致性算法

ZAB:zookeeper 原子广播

过半通过 两段提交

## MyBatis



## MySQL

### 学习技巧

```
获取官网mysql提供的数据可进行很完整的技术实例练习 
--导入sql脚本
source sql脚本路径 
--设置sql执行时间可查配置
set profiling =1;  
--查看sql执行时间
show profiles;
--查看数据需要多少数据也才能找到对应数据
select count(*) from film_actor;
show status like 'last_query_cost';
可以看到这条查询语句大概需要做1104个数据页才能找到对应的数据，这是经过一系列的统计信息计算来的
--查看所有mysql参数
show variables;
--查看mysql连接端
show processlist;
```

### 索引优点

```
1、大大减少了服务器需要扫描的数据量
2、帮助服务器避免排序和临时表
3、将随机io变成顺序io
```

### 索引的用处

```
1、快速查找匹配WHERE子句的行
2、从consideration中消除行,如果可以在多个索引之间进行选择，mysql通常会使用找到最少行的索引
3、如果表具有多列索引，则优化器可以使用索引的任何最左前缀来查找行
4、当有表连接的时候，从其他表检索行数据
5、查找特定索引列的min或max值
6、如果排序或分组时在可用索引的最左前缀上完成的，则对表进行排序和分组
7、在某些情况下，可以优化查询以检索值而无需查询数据行
```

### 索引匹配方式

```
1、全值匹配
    全值匹配指的是和索引中的所有列进行匹配
    explain select * from staffs where name = 'July' and age = '23' and pos = 'dev';
2、匹配最左前缀
    只匹配前面的几列
    explain select * from staffs where name = 'July' and age = '23';
    explain select * from staffs where name = 'July';
3、匹配列前缀
    可以匹配某一列的值的开头部分
    explain select * from staffs where name like 'J%';
    explain select * from staffs where name like '%y';
4、匹配范围值
	可以查找某一个范围的数据
	explain select * from staffs where name > 'Mary';
5、精确匹配某一列并范围匹配另外一列
	可以查询第一列的全部和第二列的部分
	explain select * from staffs where name = 'July' and age > 25;
6、只访问索引的查询
    查询的时候只需要访问索引，不需要访问数据行，本质上就是覆盖索引
    explain select name,age,pos from staffs where name = 'July' and age = 25 and pos = 'dev';
```



## Kafka

### 个人理解

```
1、kafka 消费者 可以自定义（assign） pull 消费哪个分区(partition)、从哪消费（offset） ;
2、生产者策略：
kafka生产者可以自定义将数据push到哪个分区（自定义数据分区），指定负载均衡策略（hash key不为空、组内均分）分区的作用就是提供负载均衡的能力，实现系统的高伸缩性（Scalability）
3、kafka只有分区leader才有存放数据的权限，follwer只能读取leader数据进行同步；
4、多线程异步处理消费消息，Consumer程序不要开启自动提交位移，而是要应用程序手动提交位移。
```

### kafka配置参数详情

```
1、kafka对未订阅topic offset的首次消费策略
auto.offset.reset=latest
earliest：自动将偏移量重置为最早的偏移量
latest： 自动将偏移量重置为最新的偏移量
none： 如果未找到消费者组的先前偏移量，则向消费者抛出异常

2、自动提交配置
enable.auto.commit = true  默认
auto.commit.interval.ms = 5000 默认

3、Ack应答，reties机制
acks=1：Leader会将Record写到其本地日志中，但会在不等待所有Follower的完全确认的情况下做出响应。在这种情况下，如果Leader在确认记录后立即失败，但在Follower复制记录之前失败，则记录将丢失。（容易丢数据）
acks=0：生产者根本不会等待服务器的任何确认。该记录将立即添加到套接字缓冲区中并视为已发送。在这种情况下，不能保证服务器已收到记录。（效率高）
acks=all：这意味着Leader将等待全套同步副本确认记录。这保证了只要至少一个同步副本仍处于活动状态，记录就不会丢失。这是最有力的保证。这等效于acks = -1设置。
acks=all
request.timeout.ms = 30000（应答延迟时间）
retries = 2147483647 默认（不包含第一次）
容易造成数据多发重复 

4、幂等
enable.idempotence= false 默认
开启时第三点必须也开启（acks=all retries>1）
在初始化期间，kafka会给生产者生成一个唯一的ID称为Producer ID或PID。PID和序列号与消息捆绑在一起，然后发送给Broker。由于序列号从零开始并且单调递增，因此，仅当消息的序列号比该PID / TopicPartition对中最后提交的消息正好大1时，Broker才会接受该消息。如果不是这种情况，则Broker认定是生产者重新发送该消息

5、事务0.11版本后支持
--消费者端配置
isolation.level	=  read_uncommitted
--生产者端
transactional.id= 同一时刻不能重复
enable.idempotence=true
acks=all/-1
retries=3
request.timeout.ms = 30000（应答延迟时间）
```

### kafka 同步机制

```
1、0.11版本之前同步数据会出现 数据不一致 丢失数据的情况；
2、ISR:In-sync-replicas,同步副本集和
3、leader epoch保证数据一致不丢数据主要是看 [epoch,offset]
  leader的offset永远大于follower的offset,当leader宕机后，被推举成为新leader的follower会去checkpoint文件获取缓存拿到之前的offset并将 epoch+1, 下一次接收到的消息将会放在offset+1处，等待原leader重新启动时再去同步数据，这样保证了数据一致和不丢数据的目的
```

### kafka 优化注意点

```
1. 不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。

2. 设置 acks = all。acks 是 Producer 的一个参数，代表了你对“已提交”消息的定义。如果设置成 
all，则表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。这是最高等级的“已提 
交”定义。 

3. 设置 retries 为一个较大的值。这里的 retries 同样是 Producer 的参数，对应前面提到的 
Producer 自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retries > 0 的 
Producer 能够自动重试消息发送，避免消息丢失。 

4. 设置 unclean.leader.election.enable = false。这是 Broker 端的参数，它控制的是哪些 Broke 
有资格竞选分区的 Leader。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 
Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false，即不允许这种情况的发生。 

5. 设置 replication.factor >= 3。这也是 Broker 端的参数。其实这里想表述的是，最好将消息多保 
存几份，毕竟目前防止消息丢失的主要机制就是冗余。 

6. 设置 min.insync.replicas > 1。这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副 
本才算是“已提交”。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1。 

7. 确保 replication.factor > min.insync.replicas。如果两者相等，那么只要有一个副本挂机，整个 
分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基 
础上完成。推荐设置成 replication.factor = min.insync.replicas + 1。 

8. 确保消息消费完成再提交。Consumer 端有个参数 enable.auto.commit，最好把它设置成 
false，并采用手动提交位移的方式。就像前面说的，这对于单 Consumer 多线程处理的场景而言 
是至关重要的


```

## Spring

### 源码学习方法

```
1、不要专注细节；
2、看注释（接口 类 方法）；
3、见名知意；
4、大胆猜测，小心验证；
5、画图（时序图 结构图 总结图）；
6、坚持（）；

```

### beanFactory与 factoryBean的区别
```
BeanFactory：是IOC容器的核心接口，它的职责包括：实例化、定位、配置应用程序中的对象及建立这些对象间的依赖;
它和ApplicationContext就是spring框架的两个IOC容器，现在一般使用ApplicationnContext，其不但包含了BeanFactory的作用，同时还进行更多的扩展，使用级别比beanFactory高

FactoryBean：也是接口，在bean实例化加上了简单工厂与装饰模式当实例化Bean过程比较复杂，定制实例化Bean的逻辑才是上策。
```

### spring 如何解决循环依赖问题
三级缓存
singletonObjects主要存放的是单例对象，属于第一级缓存；
earlySingletonObjects经过了实例化尚未初始化的对象，属于第二级缓存
singletonFactories属于单例工厂对象，属于第三级缓存；
Spring首先从singletonObjects中尝试获取，如果获取不到并且对象在创建中，
则尝试从earlySingletonObjects中获取，如果还是获取不到并且允许从singletonFactories通过getObject获取，
则通过singletonFactory.getObject()获取。如果获取到了则移除对应的singletonFactory,
将singletonObject放入到earlySingletonObjects，其实就是将三级缓存提升到二级缓存,这个就是缓存升级。
spring在进行对象创建的时候，会依次从一级、二级、三级缓存中寻找对象，如果找到直接返回。
由于是初次创建，只能从第三级缓存中找到(实例化阶段放入进去的)，
创建完实例，然后将缓存放到第一级缓存中。下次循环依赖的再直接从一级缓存中就可以拿到实例对象了

## SpingBoot 

### 配置文件加在顺序及优先级

```
1 在命令行中传入的参数。
2. SPRING APPLICATION JSON中的属性。 SPRING_APPLICATION—JSON是以JSON格式配置在系统环境变量中的内容。
3. java:comp/env中的JNDI 属性。
4. Java的系统属性， 可以通过System.getProperties()获得的内容。
5 操作系统的环境变量 。
6 通过random.*配置的随机属性。
7 位于当前应用 jar 包之外， 针对不同{profile}环境的配置文件内容， 例如application-{profile}.properties或是YAML定义的配置文件。
8 位于当前应用 jar 包之内 ， 针对不同{profile}环境的配置文件内容，例如application-{profile}.properties或是YAML定义的配置文件。
9 位于当前应用jar包之外的application.properties和YAML配置内容。
10位于当前应用jar包之内的application.properties和YAML配置内容。
11在@Configuration注解修改的类中，通过@PropertySource注解定义的属性。
12应用默认属性，使用SpringApplication.setDefaultProperties 定义的内容。
```

### 常见注解

```
@EnableDiscoveryClient:能够让注册中心(Consul、Nacos)发现，并扫描到该服务
@EnableCircuitBreaker:SpringCloud中使用断路器（生产端）
@FeignClient: 定义微服务发布名称，url, 熔断处理回调等
```



## SpringCloud

目前对springcloud 理解不够 很多都看不懂 需要二次学习

## 数据结构



## LINUX

管道 |

```
ls -l /etc | more  使用管道拿到/etc目录下所有文件列表 进行分页查看
优先级 $$>|>$BASHPID
$$ 获取当前线程  
$BASHPID 获取当前线程 但级别比$$低获取的线程

```



## 实用学习网址

```
数据结构排序算法过程动图：https://visualgo.net/zh
数据结构执行过程动图：https://www.cs.usfca.edu/~galles/visualization/Algorithms.html
各类学习资料：https://practice.geeksforgeeks.org

```

## 面试技巧

```
1、不要准备的100%才去尝试面试，面试过程也可查漏补缺
2、网约车 +亿级+ JVM+Redis+Zookeeper+Mysql+设计模式+多线程高并发
3、一对一简历 针对公司做简历
4、不能说原公司缺点
5、简历好坏决定面试机会，敢写技术到简历中 持续更新简历会越来越值钱
6、投简历工作日 上午 9点至10点
7、个人形象多注意 自信
8、提前5~10分钟到面试公司
9、多个office先都答应，之后再仔细考虑筛选 或者先去试用两天 不合适再pass
10、持续学习能超过周边80%的人 
11、个人博客 git源码 
12、不写离职原因
13、别怕丢人大胆说 朋友口吻
14、业务名称服务器使用linux版本 内存cpu 代码量 数据库表名 表个数 字段 
15、架构的思考
16、缺点 不太擅长和需求人员打交道现在在改进 自尊心太强，这点不太好在改
17、离职原因 ：个人原因追求更好的平台环境（不是频繁跳槽，毕业后每份工作都是两年左右，能沉淀下来 踏实干事持续学习新技术）
```

简历内容：

jvm调优、sql优化、接口访问压力改造、架构设计

一对一简历 针对公司做简历

不写离职原因