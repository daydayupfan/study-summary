1、什么是死锁（dead Lock）?
两个线程或两个以上线程都在等待对方执行完毕才能继续往下执行的时候就发生了死锁。结果就是这些线程都陷入了无限的等待中。
t1等待t2线程执行结束进行之后的操作，同样t2也在等待t1执行结束。 

2、产生死锁的四个必要条件
互斥条件：一个资源每次只能被一个进程使用。
保持和请求条件：一个进程因请求资源而阻塞时，对已获得资源保持不放。
不可剥夺性：进程已获得资源，在未使用完成前，不能被剥夺。
循环等待条件（闭环）：若干进程之间形成一种头尾相接的循环等待资源关系。

3、Synchronized实现原理
使用工具查看class文件编译成的汇编指令可知晓，其实现使用了监控器锁（monitor）进行实现
monitorenter：当monitor计数为0时，计数+1获得所有权，若同一线程多次操作将累加计数，其他线程查看计数！=0将进行阻塞等待资源释放;
monitorexit:当计数累减为0时进行资源释放，其他阻塞线程就可尝试获取所有权；
同步方法使用的是常量池标志ACC_SYNCHRONIZED.

4、wait、notify、notifyAll、yield
wait: 会释放锁
notify: 唤醒线程但不释放锁
notifyAll: 唤醒所有线程
yield:暂停当前执行线程，将Running状态转变为Runnable状态

5、内存屏障
Store：将处理器缓存的数据刷新到内存中。
Load：将内存存储的数据拷贝到处理器的缓存中。
LoadLoad:该屏障确保Load1数据的装载先于Load2及其后所有装载指令的的操作
StoreStore:该屏障确保Store1立刻刷新数据到内存(使其对其他处理器可见)的操作先于Store2及其后所有存储指令的操作
LoadStore:确保Load1的数据装载先于Store2及其后所有的存储指令刷新数据到内存的操作
StoreLoad:该屏障确保Store1立刻刷新数据到内存的操作先于Load2及其后所有装载装载指令的操作。
它会使该屏障之前的所有内存访问指令(存储指令和访问指令)完成之后,才执行该屏障之后的内存访问指令

6、线程池
```
ThreadPoolExecutor参数：
corePoolSize –保留在池中的线程数（即使它们处于空闲状态），除非设置了allowCoreThreadTimeOut
maximumPoolSize –池中允许的最大线程数
keepAliveTime –当线程数大于内核数时，这是多余的空闲线程将在终止之前等待新任务的最长时间。
unit – keepAliveTime参数的时间单位
workQueue –用于在执行任务之前保留任务的队列。 此队列将仅保存execute方法提交的Runnable任务。
threadFactory: 线程工厂(看看阿里华山派)
handler –因达到线程边界和队列容量而被阻止执行时使用的处理程序
```

```
拒绝策略
ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。（默认） 
ThreadPoolExecutor.DiscardPolicy：丢弃任务，但是不抛出异常。 
ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新提交被拒绝的任务
ThreadPoolExecutor.CallerRunsPolicy：由调用线程（提交任务的线程）处理该任务
```

运行流程
![](E:\ideaWorkSpace2019\study\study-summary\多线程\images\线程池运行流程.png)


7、阻塞队列对比

```
多线程情况少用list Set 多用quenue
ConcurrentHashMap 写效率低 读取效率极高
ConcurrentSkipListMap：跳表（redis sort_set也是这种数据结构）
ConcurrentLinkedDeque：CAS
ConcurrentLinkedQueue：CAS的双端队列

CopyOnWriteArrayList、CopyOnWriteArraySet：对写操作进行加锁ReentrantLock,其中CopyOnWriteArraySet基于CopyOnWriteArrayList而实现

LinkedBlockingQueue：无界队列（最大Integer.MAX_VALUE）FIFO tail存放的是最新进入的队列数据 head是队列中存在时间最长的数据(线程池高频使用)
LinkedTransferQueue：FIFO
LinkedBlockingDeque：双端阻塞队列（最大Integer.MAX_VALUE）
ArrayBlockingQueue：固定大小的 使用ReentrantLock实现，可选择非公平/公平锁 可以实现生产者消费者
PriorityBlockingQueue:ReentrantLock（CAS +volatile）实现
DelayQueue:使用PriorityQueue与ReentrantLock（CAS +volatile）实现
SynchronousQueue：容量为零，不能进行数据添加只能用于给另一个线程传递数据（Exchanger）CAS+Volatile+LockSupport (线程池高频使用)


ReentrantLock: 内部是由AQS (CAS(unsafe类)+LockSupport(Unsafe))实现的

CountDownLatch: 内部AQS实现 根据源码可知 它支持多个线程同时执行-->Sync(5);

```

8、线程池execute方法解析：
```
// 执行命令，其中命令（下面称任务）对象是Runnable的实例
public void execute(Runnable command) {
    // 判断命令（任务）对象非空
    if (command == null)
        throw new NullPointerException();
    // 获取ctl的值
    int c = ctl.get();
    // 判断如果当前工作线程数小于核心线程数，则创建新的核心线程并且执行传入的任务
    if (workerCountOf(c) < corePoolSize) {
        if (addWorker(command, true))
            // 如果创建新的核心线程成功则直接返回
            return;
        // 这里说明创建核心线程失败，需要更新ctl的临时变量c
        c = ctl.get();
    }
    // 走到这里说明创建新的核心线程失败，也就是当前工作线程数大于等于corePoolSize
    // 判断线程池是否处于运行中状态，同时尝试用非阻塞方法向任务队列放入任务（放入任务失败返回false）
    if (isRunning(c) && workQueue.offer(command)) {
        int recheck = ctl.get();
        // 这里是向任务队列投放任务成功，对线程池的运行中状态做二次检查
        // 如果线程池二次检查状态是非运行中状态，则从任务队列移除当前的任务调用拒绝策略处理之（也就是移除前面成功入队的任务实例）
        if (! isRunning(recheck) && remove(command))
            // 调用拒绝策略处理任务 - 返回
            reject(command);
        // 走到下面的else if分支，说明有以下的前提：
        // 0、待执行的任务已经成功加入任务队列
        // 1、线程池可能是RUNNING状态
        // 2、传入的任务可能从任务队列中移除失败（移除失败的唯一可能就是任务已经被执行了）
        // 如果当前工作线程数量为0，则创建一个非核心线程并且传入的任务对象为null - 返回
        // 也就是创建的非核心线程不会马上运行，而是等待获取任务队列的任务去执行
        // 如果前工作线程数量不为0，原来应该是最后的else分支，但是可以什么也不做，因为任务已经成功入队列，总会有合适的时机分配其他空闲线程去执行它
        else if (workerCountOf(recheck) == 0)
            addWorker(null, false);
    }
    // 走到这里说明有以下的前提：
    // 0、线程池中的工作线程总数已经大于等于corePoolSize（简单来说就是核心线程已经全部懒创建完毕）
    // 1、线程池可能不是RUNNING状态
    // 2、线程池可能是RUNNING状态同时任务队列已经满了
    // 如果向任务队列投放任务失败，则会尝试创建非核心线程传入任务执行
    // 创建非核心线程失败，此时需要拒绝执行任务
    else if (!addWorker(command, false))
        // 调用拒绝策略处理任务 - 返回
        reject(command);
}
```
